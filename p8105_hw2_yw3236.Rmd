---
title: "p8105_hw2_yw3236"
output: github_document
author: "Yishan Wang"
date: 2018-10-01
---

# Problem 1

```{r set up library, include = FALSE}
library(tidyverse)
```

### Read and clean the data 
* Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.

* Convert the entry variable from character (`YES` vs `NO`) to a logical variable.

```{r import and clean data}
transit_data = 
  read_csv(file = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(., "line", "station_name", "station_latitude", "station_longitude", "route1":"route11", "entry", "vending", "entrance_type", "ada") %>%
  mutate(., entry = recode(entry, YES = TRUE, NO = FALSE))
```

### A short paragraph about this dataset 
The variables that dataset contains are `line`, `station_name`, `station_latitude`, `station_longitude`, `rout1` to `rout11`, `entry`, `vending`, `entrence_type`, `ada`. After reading the dataset to R, I used `janitor::clean_names()` to clean the variable names. Then I used `select` to selecte the variables that I want to keep in the dataset and delete other unwanted variables. Lastly, I used `mutate` and `recode` to convert the `entry` from character variable to logical variable. The dimension of the resulting dataset is 1868 x 19. Yes, the data are tidy.

### Answering the questons

```{r}
nrow(distinct(transit_data, line, station_name))
```

The number of the distinct stations are `r nrow(distinct(transit_data, line, station_name))`.

```{r}
station_ada = 
  distinct(transit_data, line, station_name, .keep_all = TRUE) %>%
  dplyr::filter(., ada == TRUE)
nrow(station_ada)
```

There are `r nrow(station_ada)` stations that are ADA compliant.

```{r}
vending_no = transit_data %>%
  dplyr::filter(., vending == 'NO')

prop = nrow(dplyr::filter(vending_no, entry == TRUE)) / nrow(vending_no)
prop
```

The proportion of station entrances / exists without vending allow entrance is `r prop`.

```{r}
reform_data = transit_data %>%
  gather(., key = route_num, value = route_name, route1:route11) %>%
  dplyr::filter(., route_name == 'A')

dist_station_serve_A = distinct(reform_data, line, station_name, .keep_all = TRUE)
nrow(dist_station_serve_A)

dist_ada_station_serve_A = dplyr::filter(dist_station_serve_A, ada == TRUE)
nrow(dist_ada_station_serve_A)
```

There are `r nrow(dist_station_serve_A)` distinct stations serve A train, and `r nrow(dist_ada_station_serve_A)` of them are ADA compliant.

# Problem 2

### Read and clean the Mr. Trash Wheel sheet
* Specify the sheet in the Excel file and to omit columns containing notes.

* Omit rows that do not include dumpster-specific data.

* Rounds the number of sports balls to the nearest integer and converts the result to an integer variable.

```{r}
trash_data = 
  readxl::read_excel("./HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 1, range = cellranger::cell_cols("A:N")) %>% 
  janitor::clean_names() %>%
  dplyr::filter(., !is.na(dumpster)) %>%
  mutate(sports_balls = round(sports_balls)) %>%
  mutate(sports_balls = as.integer(.$sports_balls))
```

### Read and clean precipitation data for 2016 and 2017
* For each, omit rows without precipitation data and add a variable year.

```{r}
prec_17 =
  readxl::read_excel("./HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 3, range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() 

names(prec_17) = as.matrix(prec_17[1, ])
prec_17 = prec_17[-1, ]
prec_17[] = lapply(prec_17, function(x) type.convert(as.character(x))) 

prec_17_new = prec_17 %>%
  janitor::clean_names() %>%
  dplyr::filter(., !is.na(.$total)) %>%
  mutate(., year = '2017') 
```

```{r}
prec_16 =
  readxl::read_excel("./HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 4, range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() 

names(prec_16) = as.matrix(prec_16[1, ])
prec_16 = prec_16[-1, ]
prec_16[] = lapply(prec_16, function(x) type.convert(as.character(x))) 

prec_16_new = prec_16 %>%
  janitor::clean_names() %>%
  dplyr::filter(., !is.na(.$total)) %>%
  mutate(., year = '2016') 
```

* Combine datasets and convert month to a character variable.

```{r}
prec = left_join(prec_16_new, prec_17_new, by = "month") 
prec

prec %>%
  dplyr::rename(., total_2016 = total.x, total_2017 = total.y) %>%
  select(., -year.x, -year.y) %>%
  mutate(., month.abb[month]) %>%
  select(., -month) %>%
  dplyr::rename(., month = `month.abb[month]`) %>%
  select(., month, total_2016, total_2017)
```

### A paragraph about these data

```{r}
nrow(prec_17_new)
nrow(prec_16_new)
```

```{r}
trash_data_16 = trash_data %>% 
  dplyr::filter(., year == '2016')
```

There are `r nrow(prec_17_new)` observations in 2017 precipitation dataset. There are `r nrow(prec_16_new)` observations in 2016 precipitation dataset. The key variable is `total`, which precipitation total for each month. The total precipitation in 2017 is `r sum(prec_17_new$total) - tail(prec_17_new$total, n = 1)`. The median number of sports balls in a dumpster in 2016 is `r median(trash_data_16$sports_balls)`.

# Problem 3

### Load and read the data from the `p8105.datasets` package

```{r}
devtools::install_github("p8105/p8105.datasets")
```

```{r}
library(p8105.datasets)
```

```{r}
data(brfss_smart2010)
```

### Format the dataset
* Format the data to use appropriate variable names.

* Focus on the “Overall Health” topic.

* Exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation.

* Structure data so that responses (excellent to poor) are variables taking the value of `Data_value`.

* Reate a new variable showing the proportion of responses that were “Excellent” or “Very Good”

```{r}
new = brfss_smart2010 %>%
  janitor::clean_names() %>%
  dplyr::rename(., state = locationabbr, county = locationdesc) %>%
  dplyr::filter(., topic == "Overall Health") %>%
  select(., -class, -topic, -question, -sample_size, -(confidence_limit_low : geo_location)) %>%
  spread(., key = response, value = data_value) %>%
  janitor::clean_names() %>%
  select(., year:county, excellent, very_good, good, fair, poor) %>%
  mutate(., excellent_or_very_good = (excellent + very_good) / (excellent + very_good + good + fair + poor))
```

### Do or answer the questions
```{r}
distinct(new, county)
distinct(new, state)
new %>%
  count(state)
```

There are `r nrow(distinct(new, county))` unique locations that are included in the dataset. Yes, every state is represented in the data set. The state that is observed most is NJ (146 times).

```{r}
new_2002 = new %>%
  dplyr::filter(., year == '2002') 

median(new_2002$excellent, na.rm = TRUE)
```

The median of "Excellent" is `r median(new_2002$excellent, na.rm = TRUE)`.
